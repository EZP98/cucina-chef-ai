{
  "version": 3,
  "sources": ["../../../functions/api/analyze-pantry.ts", "../../../functions/api/chat.ts", "functionsRoutes-0.2155934051567211.mjs", "../../../../../../../opt/homebrew/lib/node_modules/wrangler/node_modules/path-to-regexp/src/index.ts", "../../../../../../../opt/homebrew/lib/node_modules/wrangler/templates/pages-template-worker.ts", "../../../../../../../opt/homebrew/lib/node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts", "../../../../../../../opt/homebrew/lib/node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts", "../bundle-4uoDjQ/middleware-insertion-facade.js", "../../../../../../../opt/homebrew/lib/node_modules/wrangler/templates/middleware/common.ts", "../bundle-4uoDjQ/middleware-loader.entry.ts"],
  "sourceRoot": "/Users/eziopappalardo/Documents/cucina/.wrangler/tmp/pages-XzSetR/functionsWorker-0.46906118167794986.mjs",
  "sourcesContent": ["// Cloudflare Pages Function for Pantry Image Analysis with Claude Vision\n\ninterface Env {\n  ANTHROPIC_API_KEY: string;\n}\n\nexport const onRequestPost: PagesFunction<Env> = async (context) => {\n  const { request, env } = context;\n\n  const corsHeaders = {\n    'Access-Control-Allow-Origin': '*',\n    'Access-Control-Allow-Methods': 'POST, OPTIONS',\n    'Access-Control-Allow-Headers': 'Content-Type',\n  };\n\n  try {\n    const { image } = await request.json() as { image: string };\n\n    if (!image) {\n      return new Response(JSON.stringify({ error: 'Image is required' }), {\n        status: 400,\n        headers: { 'Content-Type': 'application/json', ...corsHeaders },\n      });\n    }\n\n    // Extract base64 data and media type\n    const matches = image.match(/^data:([^;]+);base64,(.+)$/);\n    if (!matches) {\n      return new Response(JSON.stringify({ error: 'Invalid image format' }), {\n        status: 400,\n        headers: { 'Content-Type': 'application/json', ...corsHeaders },\n      });\n    }\n\n    const mediaType = matches[1] as 'image/jpeg' | 'image/png' | 'image/gif' | 'image/webp';\n    const imageData = matches[2];\n\n    // Call Claude Vision API\n    const response = await fetch('https://api.anthropic.com/v1/messages', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'x-api-key': env.ANTHROPIC_API_KEY,\n        'anthropic-version': '2023-06-01',\n      },\n      body: JSON.stringify({\n        model: 'claude-haiku-4-5-20251001',\n        max_tokens: 1000,\n        messages: [\n          {\n            role: 'user',\n            content: [\n              {\n                type: 'image',\n                source: {\n                  type: 'base64',\n                  media_type: mediaType,\n                  data: imageData,\n                },\n              },\n              {\n                type: 'text',\n                text: `Analizza questa foto di una dispensa/frigorifero/scaffale cucina.\nIdentifica TUTTI gli ingredienti alimentari visibili nella foto.\n\nRispondi SOLO con un JSON valido nel formato:\n{\n  \"ingredients\": [\n    {\"name\": \"Nome Ingrediente\", \"qty\": \"quantit\u00E0 stimata\"},\n    ...\n  ]\n}\n\nRegole:\n- Usa nomi in italiano\n- Stima la quantit\u00E0 (es: \"3\", \"200g\", \"1 bottiglia\", \"1 confezione\")\n- Includi SOLO cibi/ingredienti, non utensili o contenitori vuoti\n- Sii specifico (es: \"Parmigiano Reggiano\" invece di \"formaggio\")\n- Se non riesci a identificare un ingrediente, omettilo`\n              }\n            ],\n          },\n        ],\n      }),\n    });\n\n    if (!response.ok) {\n      const error = await response.text();\n      console.error('Claude Vision API error:', error);\n      return new Response(JSON.stringify({ error: 'Vision API error' }), {\n        status: 500,\n        headers: { 'Content-Type': 'application/json', ...corsHeaders },\n      });\n    }\n\n    const result = await response.json() as {\n      content: Array<{ type: string; text?: string }>;\n    };\n\n    // Extract text from response\n    const textContent = result.content.find(c => c.type === 'text');\n    if (!textContent?.text) {\n      return new Response(JSON.stringify({ error: 'No response from AI' }), {\n        status: 500,\n        headers: { 'Content-Type': 'application/json', ...corsHeaders },\n      });\n    }\n\n    // Parse JSON from response\n    try {\n      // Extract JSON from markdown code block if present\n      let jsonText = textContent.text;\n      const jsonMatch = jsonText.match(/```(?:json)?\\s*([\\s\\S]*?)```/);\n      if (jsonMatch) {\n        jsonText = jsonMatch[1].trim();\n      }\n\n      const ingredients = JSON.parse(jsonText);\n      return new Response(JSON.stringify(ingredients), {\n        headers: { 'Content-Type': 'application/json', ...corsHeaders },\n      });\n    } catch (parseError) {\n      console.error('JSON parse error:', parseError, textContent.text);\n      return new Response(JSON.stringify({\n        error: 'Could not parse ingredients',\n        raw: textContent.text\n      }), {\n        status: 500,\n        headers: { 'Content-Type': 'application/json', ...corsHeaders },\n      });\n    }\n\n  } catch (error) {\n    console.error('Analyze pantry error:', error);\n    return new Response(JSON.stringify({ error: 'Internal server error' }), {\n      status: 500,\n      headers: { 'Content-Type': 'application/json', ...corsHeaders },\n    });\n  }\n};\n\n// Handle CORS preflight\nexport const onRequestOptions: PagesFunction = async () => {\n  return new Response(null, {\n    headers: {\n      'Access-Control-Allow-Origin': '*',\n      'Access-Control-Allow-Methods': 'POST, OPTIONS',\n      'Access-Control-Allow-Headers': 'Content-Type',\n    },\n  });\n};\n", "// Cloudflare Pages Function for Gusto Chat with RAG\n\ninterface Env {\n  ANTHROPIC_API_KEY: string;\n}\n\n// RAG Index loaded from static file\nlet ragIndex: RagIndex | null = null;\n\ninterface RagChunk {\n  id: number;\n  src: string;\n  pg: number;\n  txt: string;\n}\n\ninterface RagIndex {\n  chunks: RagChunk[];\n}\n\n// Simple BM25-like scoring for keyword search\nfunction tokenize(text: string): string[] {\n  return text.toLowerCase()\n    .replace(/[^\\w\\s\u00E0\u00E8\u00E9\u00EC\u00F2\u00F9\u00E1\u00E9\u00ED\u00F3\u00FA]/g, ' ')\n    .split(/\\s+/)\n    .filter(t => t.length > 2);\n}\n\nfunction computeBM25Score(query: string[], doc: string[], avgDocLen: number): number {\n  const k1 = 1.5;\n  const b = 0.75;\n  const docLen = doc.length;\n\n  let score = 0;\n  const docFreq = new Map<string, number>();\n\n  for (const term of doc) {\n    docFreq.set(term, (docFreq.get(term) || 0) + 1);\n  }\n\n  for (const term of query) {\n    const tf = docFreq.get(term) || 0;\n    if (tf > 0) {\n      const idf = Math.log(1 + 1); // Simplified IDF\n      const tfNorm = (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * docLen / avgDocLen));\n      score += idf * tfNorm;\n    }\n  }\n\n  return score;\n}\n\n// Search for relevant chunks\nfunction searchChunks(query: string, chunks: RagChunk[], topK: number = 5): RagChunk[] {\n  const queryTokens = tokenize(query);\n\n  // Calculate average doc length\n  const avgDocLen = chunks.reduce((sum, c) => sum + tokenize(c.txt).length, 0) / chunks.length;\n\n  // Score all chunks\n  const scored = chunks.map(chunk => ({\n    chunk,\n    score: computeBM25Score(queryTokens, tokenize(chunk.txt), avgDocLen)\n  }));\n\n  // Sort by score and return top K\n  return scored\n    .filter(s => s.score > 0)\n    .sort((a, b) => b.score - a.score)\n    .slice(0, topK)\n    .map(s => s.chunk);\n}\n\n// Format context from chunks (without source attribution)\nfunction formatContext(chunks: RagChunk[]): string {\n  if (chunks.length === 0) return '';\n\n  let context = '\\n\\n<relevant_knowledge>\\n';\n\n  for (const chunk of chunks) {\n    context += `${chunk.txt}\\n\\n`;\n  }\n\n  context += '</relevant_knowledge>';\n\n  return context;\n}\n\nexport const onRequestPost: PagesFunction<Env> = async (context) => {\n  const { request, env } = context;\n\n  const corsHeaders = {\n    'Access-Control-Allow-Origin': '*',\n    'Access-Control-Allow-Methods': 'POST, OPTIONS',\n    'Access-Control-Allow-Headers': 'Content-Type',\n  };\n\n  try {\n    const { message, history = [], menuMode = false, dietMode = 'none' } = await request.json() as {\n      message: string;\n      history?: Array<{ role: string; content: string }>;\n      menuMode?: boolean;\n      dietMode?: string;\n    };\n\n    if (!message) {\n      return new Response(JSON.stringify({ error: 'Message is required' }), {\n        status: 400,\n        headers: { 'Content-Type': 'application/json', ...corsHeaders },\n      });\n    }\n\n    // Load RAG index if not cached\n    if (!ragIndex) {\n      try {\n        const ragResponse = await fetch(new URL('/rag_index.json', request.url));\n        if (ragResponse.ok) {\n          ragIndex = await ragResponse.json() as RagIndex;\n          console.log(`RAG index loaded: ${ragIndex.chunks.length} chunks`);\n        }\n      } catch (e) {\n        console.log('RAG index not available, continuing without RAG');\n      }\n    }\n\n    // Search for relevant context\n    let ragContext = '';\n    if (ragIndex && ragIndex.chunks) {\n      const relevantChunks = searchChunks(message, ragIndex.chunks, 5);\n      if (relevantChunks.length > 0) {\n        ragContext = formatContext(relevantChunks);\n        console.log(`Found ${relevantChunks.length} relevant chunks`);\n      }\n    }\n\n    // Build messages array\n    const messages = [\n      ...history,\n      { role: 'user', content: message }\n    ];\n\n    // Enhanced system prompt with RAG context\n    const systemPrompt = `<role>\nYou are Gusto, a passionate and knowledgeable culinary expert with deep expertise in Italian, French, and international cuisine. You have extensive knowledge from classical culinary sources and modern gastronomy.\n</role>\n\n<language_rule>\nCRITICAL: Detect the user's language from their message and ALWAYS respond in that same language. Never ask users to switch languages. If they write in Italian, respond in Italian. If in English, respond in English. If in French, respond in French. And so on for any language.\n</language_rule>\n\n<personality>\n- Warm, friendly, and encouraging like a beloved family chef\n- Passionate about food and cooking traditions\n- Practical and helpful, focused on making cooking accessible\n- Share knowledge naturally without being pedantic\n</personality>\n\n<knowledge>\nYou have deep knowledge of:\n- Classical French cuisine (techniques, sauces, preparations)\n- Traditional Italian cooking (regional recipes, pasta, risotto)\n- Flavor pairings and ingredient combinations\n- Cooking techniques from basic to advanced\n- Ingredient substitutions and adaptations\n</knowledge>\n\n<rag_priority>\nCRITICAL: When <relevant_knowledge> is provided below, it contains VERIFIED and UP-TO-DATE information that MUST take precedence over your training data.\n\nRules for using RAG context:\n1. If the context mentions specific facts (restaurant names, star ratings, dish names, ingredients), use EXACTLY those details - do not substitute with your own knowledge\n2. If the context says a chef has \"3 stars\" or works at \"La Rei Natura\", use those exact facts even if your training says otherwise\n3. For Michelin-starred chefs and their signature dishes, the RAG context is MORE ACCURATE than your training data\n4. If no relevant context is provided, you may use your general culinary knowledge\n5. NEVER invent specific details (star ratings, restaurant names, dish compositions) that are not in the context\n6. If unsure about specific facts not in the context, give general information or say you'd need to verify\n\nSpeak naturally as an expert - don't mention \"according to my sources\" or cite the RAG. Just use the information as your own knowledge.\n</rag_priority>\n\n<rules>\n- Keep responses concise but complete (2-4 paragraphs unless a full recipe is requested)\n- When suggesting recipes, offer 2-3 options with brief descriptions\n- For full recipes, include: ingredients list, clear steps, timing, and practical tips\n- NEVER use emoji in your responses - the UI has a hand-drawn style that doesn't use emoji\n- Give practical tips a home cook can actually use\n- If asked about ingredients, suggest what to cook with them\n- Adapt complexity to user's apparent skill level\n</rules>\n\n<response_format>\nFor recipe suggestions: Brief intro + 2-3 options with name, description, time\nFor full recipes: Ingredients \u2192 Steps \u2192 Tips\nFor questions: Direct answer with practical context\n</response_format>\n${menuMode ? `\n<menu_mode>\nIMPORTANT: The user has MENU MODE enabled. They want a COMPLETE MENU, not just a single dish.\n\nWhen responding:\n1. Create a structured menu with multiple courses (antipasto, primo, secondo, contorno, dolce)\n2. Each course should have: name, brief description, estimated prep time\n3. Suggest wine pairings if appropriate\n4. Consider ingredient availability and cooking time logistics\n5. Make sure courses complement each other in flavors and textures\n6. Format the menu clearly with sections for each course\n\nExample structure:\n**Menu [tema/occasione]**\n\n**Antipasto** - Nome piatto\nBreve descrizione...\n\n**Primo** - Nome piatto\nBreve descrizione...\n\n**Secondo** - Nome piatto\nBreve descrizione...\n\n**Contorno** - Nome piatto\nBreve descrizione...\n\n**Dolce** - Nome piatto\nBreve descrizione...\n\n**Abbinamento vini:** ...\n</menu_mode>\n` : ''}\n${dietMode && dietMode !== 'none' ? `\n<diet_mode>\nIMPORTANT: The user follows a ${\n  dietMode === 'lowcarb' ? 'LOW CARB diet - minimize carbohydrates, avoid pasta, bread, rice, potatoes. Focus on proteins, vegetables, healthy fats' :\n  dietMode === 'keto' ? 'KETOGENIC diet - very low carb (under 20-50g/day), high fat, moderate protein. Avoid all sugars, grains, most fruits. Focus on meat, fish, eggs, cheese, nuts, low-carb vegetables' :\n  dietMode === 'vegetarian' ? 'VEGETARIAN diet - no meat or fish. Eggs and dairy are OK. Suggest plant proteins like legumes, tofu, tempeh, seitan' :\n  dietMode === 'vegan' ? 'VEGAN diet - no animal products at all. No meat, fish, eggs, dairy, honey. Focus on plant-based proteins, legumes, tofu, nutritional yeast for umami' :\n  dietMode === 'glutenfree' ? 'GLUTEN-FREE diet - avoid wheat, barley, rye, spelt. Use rice, corn, quinoa, buckwheat, certified gluten-free oats. Check all sauces and processed ingredients' :\n  dietMode === 'lactosefree' ? 'LACTOSE-FREE diet - avoid milk, cream, soft cheeses. Hard aged cheeses and butter are usually OK. Suggest plant milks, lactose-free alternatives' :\n  dietMode === 'highprotein' ? 'HIGH PROTEIN diet - maximize protein intake. Focus on lean meats, fish, eggs, legumes, Greek yogurt, cottage cheese. Include protein in every meal' :\n  'specific dietary restriction'\n}.\n\nALL recipe suggestions and menus MUST comply with this diet. If the user asks for something incompatible, suggest a compliant alternative.\n</diet_mode>\n` : ''}\n${ragContext}`;\n\n    // Call Anthropic API with streaming enabled\n    const response = await fetch('https://api.anthropic.com/v1/messages', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'x-api-key': env.ANTHROPIC_API_KEY,\n        'anthropic-version': '2023-06-01',\n      },\n      body: JSON.stringify({\n        model: 'claude-haiku-4-5-20251001',\n        max_tokens: 1500,\n        stream: true,  // Enable streaming\n        system: systemPrompt,\n        messages: messages,\n      }),\n    });\n\n    if (!response.ok) {\n      const error = await response.text();\n      console.error('Anthropic API error:', error);\n      return new Response(JSON.stringify({ error: 'AI service error' }), {\n        status: 500,\n        headers: { 'Content-Type': 'application/json', ...corsHeaders },\n      });\n    }\n\n    // Return SSE stream directly\n    return new Response(response.body, {\n      headers: {\n        'Content-Type': 'text/event-stream',\n        'Cache-Control': 'no-cache',\n        'Connection': 'keep-alive',\n        ...corsHeaders\n      },\n    });\n\n  } catch (error) {\n    console.error('Chat error:', error);\n    return new Response(JSON.stringify({ error: 'Internal server error' }), {\n      status: 500,\n      headers: { 'Content-Type': 'application/json', ...corsHeaders },\n    });\n  }\n};\n\n// Handle CORS preflight\nexport const onRequestOptions: PagesFunction = async () => {\n  return new Response(null, {\n    headers: {\n      'Access-Control-Allow-Origin': '*',\n      'Access-Control-Allow-Methods': 'POST, OPTIONS',\n      'Access-Control-Allow-Headers': 'Content-Type',\n    },\n  });\n};\n", "import { onRequestOptions as __api_analyze_pantry_ts_onRequestOptions } from \"/Users/eziopappalardo/Documents/cucina/functions/api/analyze-pantry.ts\"\nimport { onRequestPost as __api_analyze_pantry_ts_onRequestPost } from \"/Users/eziopappalardo/Documents/cucina/functions/api/analyze-pantry.ts\"\nimport { onRequestOptions as __api_chat_ts_onRequestOptions } from \"/Users/eziopappalardo/Documents/cucina/functions/api/chat.ts\"\nimport { onRequestPost as __api_chat_ts_onRequestPost } from \"/Users/eziopappalardo/Documents/cucina/functions/api/chat.ts\"\n\nexport const routes = [\n    {\n      routePath: \"/api/analyze-pantry\",\n      mountPath: \"/api\",\n      method: \"OPTIONS\",\n      middlewares: [],\n      modules: [__api_analyze_pantry_ts_onRequestOptions],\n    },\n  {\n      routePath: \"/api/analyze-pantry\",\n      mountPath: \"/api\",\n      method: \"POST\",\n      middlewares: [],\n      modules: [__api_analyze_pantry_ts_onRequestPost],\n    },\n  {\n      routePath: \"/api/chat\",\n      mountPath: \"/api\",\n      method: \"OPTIONS\",\n      middlewares: [],\n      modules: [__api_chat_ts_onRequestOptions],\n    },\n  {\n      routePath: \"/api/chat\",\n      mountPath: \"/api\",\n      method: \"POST\",\n      middlewares: [],\n      modules: [__api_chat_ts_onRequestPost],\n    },\n  ]", "/**\n * Tokenizer results.\n */\ninterface LexToken {\n  type:\n    | \"OPEN\"\n    | \"CLOSE\"\n    | \"PATTERN\"\n    | \"NAME\"\n    | \"CHAR\"\n    | \"ESCAPED_CHAR\"\n    | \"MODIFIER\"\n    | \"END\";\n  index: number;\n  value: string;\n}\n\n/**\n * Tokenize input string.\n */\nfunction lexer(str: string): LexToken[] {\n  const tokens: LexToken[] = [];\n  let i = 0;\n\n  while (i < str.length) {\n    const char = str[i];\n\n    if (char === \"*\" || char === \"+\" || char === \"?\") {\n      tokens.push({ type: \"MODIFIER\", index: i, value: str[i++] });\n      continue;\n    }\n\n    if (char === \"\\\\\") {\n      tokens.push({ type: \"ESCAPED_CHAR\", index: i++, value: str[i++] });\n      continue;\n    }\n\n    if (char === \"{\") {\n      tokens.push({ type: \"OPEN\", index: i, value: str[i++] });\n      continue;\n    }\n\n    if (char === \"}\") {\n      tokens.push({ type: \"CLOSE\", index: i, value: str[i++] });\n      continue;\n    }\n\n    if (char === \":\") {\n      let name = \"\";\n      let j = i + 1;\n\n      while (j < str.length) {\n        const code = str.charCodeAt(j);\n\n        if (\n          // `0-9`\n          (code >= 48 && code <= 57) ||\n          // `A-Z`\n          (code >= 65 && code <= 90) ||\n          // `a-z`\n          (code >= 97 && code <= 122) ||\n          // `_`\n          code === 95\n        ) {\n          name += str[j++];\n          continue;\n        }\n\n        break;\n      }\n\n      if (!name) throw new TypeError(`Missing parameter name at ${i}`);\n\n      tokens.push({ type: \"NAME\", index: i, value: name });\n      i = j;\n      continue;\n    }\n\n    if (char === \"(\") {\n      let count = 1;\n      let pattern = \"\";\n      let j = i + 1;\n\n      if (str[j] === \"?\") {\n        throw new TypeError(`Pattern cannot start with \"?\" at ${j}`);\n      }\n\n      while (j < str.length) {\n        if (str[j] === \"\\\\\") {\n          pattern += str[j++] + str[j++];\n          continue;\n        }\n\n        if (str[j] === \")\") {\n          count--;\n          if (count === 0) {\n            j++;\n            break;\n          }\n        } else if (str[j] === \"(\") {\n          count++;\n          if (str[j + 1] !== \"?\") {\n            throw new TypeError(`Capturing groups are not allowed at ${j}`);\n          }\n        }\n\n        pattern += str[j++];\n      }\n\n      if (count) throw new TypeError(`Unbalanced pattern at ${i}`);\n      if (!pattern) throw new TypeError(`Missing pattern at ${i}`);\n\n      tokens.push({ type: \"PATTERN\", index: i, value: pattern });\n      i = j;\n      continue;\n    }\n\n    tokens.push({ type: \"CHAR\", index: i, value: str[i++] });\n  }\n\n  tokens.push({ type: \"END\", index: i, value: \"\" });\n\n  return tokens;\n}\n\nexport interface ParseOptions {\n  /**\n   * Set the default delimiter for repeat parameters. (default: `'/'`)\n   */\n  delimiter?: string;\n  /**\n   * List of characters to automatically consider prefixes when parsing.\n   */\n  prefixes?: string;\n}\n\n/**\n * Parse a string for the raw tokens.\n */\nexport function parse(str: string, options: ParseOptions = {}): Token[] {\n  const tokens = lexer(str);\n  const { prefixes = \"./\", delimiter = \"/#?\" } = options;\n  const result: Token[] = [];\n  let key = 0;\n  let i = 0;\n  let path = \"\";\n\n  const tryConsume = (type: LexToken[\"type\"]): string | undefined => {\n    if (i < tokens.length && tokens[i].type === type) return tokens[i++].value;\n  };\n\n  const mustConsume = (type: LexToken[\"type\"]): string => {\n    const value = tryConsume(type);\n    if (value !== undefined) return value;\n    const { type: nextType, index } = tokens[i];\n    throw new TypeError(`Unexpected ${nextType} at ${index}, expected ${type}`);\n  };\n\n  const consumeText = (): string => {\n    let result = \"\";\n    let value: string | undefined;\n    while ((value = tryConsume(\"CHAR\") || tryConsume(\"ESCAPED_CHAR\"))) {\n      result += value;\n    }\n    return result;\n  };\n\n  const isSafe = (value: string): boolean => {\n    for (const char of delimiter) if (value.indexOf(char) > -1) return true;\n    return false;\n  };\n\n  const safePattern = (prefix: string) => {\n    const prev = result[result.length - 1];\n    const prevText = prefix || (prev && typeof prev === \"string\" ? prev : \"\");\n\n    if (prev && !prevText) {\n      throw new TypeError(\n        `Must have text between two parameters, missing text after \"${(prev as Key).name}\"`,\n      );\n    }\n\n    if (!prevText || isSafe(prevText)) return `[^${escapeString(delimiter)}]+?`;\n    return `(?:(?!${escapeString(prevText)})[^${escapeString(delimiter)}])+?`;\n  };\n\n  while (i < tokens.length) {\n    const char = tryConsume(\"CHAR\");\n    const name = tryConsume(\"NAME\");\n    const pattern = tryConsume(\"PATTERN\");\n\n    if (name || pattern) {\n      let prefix = char || \"\";\n\n      if (prefixes.indexOf(prefix) === -1) {\n        path += prefix;\n        prefix = \"\";\n      }\n\n      if (path) {\n        result.push(path);\n        path = \"\";\n      }\n\n      result.push({\n        name: name || key++,\n        prefix,\n        suffix: \"\",\n        pattern: pattern || safePattern(prefix),\n        modifier: tryConsume(\"MODIFIER\") || \"\",\n      });\n      continue;\n    }\n\n    const value = char || tryConsume(\"ESCAPED_CHAR\");\n    if (value) {\n      path += value;\n      continue;\n    }\n\n    if (path) {\n      result.push(path);\n      path = \"\";\n    }\n\n    const open = tryConsume(\"OPEN\");\n    if (open) {\n      const prefix = consumeText();\n      const name = tryConsume(\"NAME\") || \"\";\n      const pattern = tryConsume(\"PATTERN\") || \"\";\n      const suffix = consumeText();\n\n      mustConsume(\"CLOSE\");\n\n      result.push({\n        name: name || (pattern ? key++ : \"\"),\n        pattern: name && !pattern ? safePattern(prefix) : pattern,\n        prefix,\n        suffix,\n        modifier: tryConsume(\"MODIFIER\") || \"\",\n      });\n      continue;\n    }\n\n    mustConsume(\"END\");\n  }\n\n  return result;\n}\n\nexport interface TokensToFunctionOptions {\n  /**\n   * When `true` the regexp will be case sensitive. (default: `false`)\n   */\n  sensitive?: boolean;\n  /**\n   * Function for encoding input strings for output.\n   */\n  encode?: (value: string, token: Key) => string;\n  /**\n   * When `false` the function can produce an invalid (unmatched) path. (default: `true`)\n   */\n  validate?: boolean;\n}\n\n/**\n * Compile a string to a template function for the path.\n */\nexport function compile<P extends object = object>(\n  str: string,\n  options?: ParseOptions & TokensToFunctionOptions,\n) {\n  return tokensToFunction<P>(parse(str, options), options);\n}\n\nexport type PathFunction<P extends object = object> = (data?: P) => string;\n\n/**\n * Expose a method for transforming tokens into the path function.\n */\nexport function tokensToFunction<P extends object = object>(\n  tokens: Token[],\n  options: TokensToFunctionOptions = {},\n): PathFunction<P> {\n  const reFlags = flags(options);\n  const { encode = (x: string) => x, validate = true } = options;\n\n  // Compile all the tokens into regexps.\n  const matches = tokens.map((token) => {\n    if (typeof token === \"object\") {\n      return new RegExp(`^(?:${token.pattern})$`, reFlags);\n    }\n  });\n\n  return (data: Record<string, any> | null | undefined) => {\n    let path = \"\";\n\n    for (let i = 0; i < tokens.length; i++) {\n      const token = tokens[i];\n\n      if (typeof token === \"string\") {\n        path += token;\n        continue;\n      }\n\n      const value = data ? data[token.name] : undefined;\n      const optional = token.modifier === \"?\" || token.modifier === \"*\";\n      const repeat = token.modifier === \"*\" || token.modifier === \"+\";\n\n      if (Array.isArray(value)) {\n        if (!repeat) {\n          throw new TypeError(\n            `Expected \"${token.name}\" to not repeat, but got an array`,\n          );\n        }\n\n        if (value.length === 0) {\n          if (optional) continue;\n\n          throw new TypeError(`Expected \"${token.name}\" to not be empty`);\n        }\n\n        for (let j = 0; j < value.length; j++) {\n          const segment = encode(value[j], token);\n\n          if (validate && !(matches[i] as RegExp).test(segment)) {\n            throw new TypeError(\n              `Expected all \"${token.name}\" to match \"${token.pattern}\", but got \"${segment}\"`,\n            );\n          }\n\n          path += token.prefix + segment + token.suffix;\n        }\n\n        continue;\n      }\n\n      if (typeof value === \"string\" || typeof value === \"number\") {\n        const segment = encode(String(value), token);\n\n        if (validate && !(matches[i] as RegExp).test(segment)) {\n          throw new TypeError(\n            `Expected \"${token.name}\" to match \"${token.pattern}\", but got \"${segment}\"`,\n          );\n        }\n\n        path += token.prefix + segment + token.suffix;\n        continue;\n      }\n\n      if (optional) continue;\n\n      const typeOfMessage = repeat ? \"an array\" : \"a string\";\n      throw new TypeError(`Expected \"${token.name}\" to be ${typeOfMessage}`);\n    }\n\n    return path;\n  };\n}\n\nexport interface RegexpToFunctionOptions {\n  /**\n   * Function for decoding strings for params.\n   */\n  decode?: (value: string, token: Key) => string;\n}\n\n/**\n * A match result contains data about the path match.\n */\nexport interface MatchResult<P extends object = object> {\n  path: string;\n  index: number;\n  params: P;\n}\n\n/**\n * A match is either `false` (no match) or a match result.\n */\nexport type Match<P extends object = object> = false | MatchResult<P>;\n\n/**\n * The match function takes a string and returns whether it matched the path.\n */\nexport type MatchFunction<P extends object = object> = (\n  path: string,\n) => Match<P>;\n\n/**\n * Create path match function from `path-to-regexp` spec.\n */\nexport function match<P extends object = object>(\n  str: Path,\n  options?: ParseOptions & TokensToRegexpOptions & RegexpToFunctionOptions,\n) {\n  const keys: Key[] = [];\n  const re = pathToRegexp(str, keys, options);\n  return regexpToFunction<P>(re, keys, options);\n}\n\n/**\n * Create a path match function from `path-to-regexp` output.\n */\nexport function regexpToFunction<P extends object = object>(\n  re: RegExp,\n  keys: Key[],\n  options: RegexpToFunctionOptions = {},\n): MatchFunction<P> {\n  const { decode = (x: string) => x } = options;\n\n  return function (pathname: string) {\n    const m = re.exec(pathname);\n    if (!m) return false;\n\n    const { 0: path, index } = m;\n    const params = Object.create(null);\n\n    for (let i = 1; i < m.length; i++) {\n      if (m[i] === undefined) continue;\n\n      const key = keys[i - 1];\n\n      if (key.modifier === \"*\" || key.modifier === \"+\") {\n        params[key.name] = m[i].split(key.prefix + key.suffix).map((value) => {\n          return decode(value, key);\n        });\n      } else {\n        params[key.name] = decode(m[i], key);\n      }\n    }\n\n    return { path, index, params };\n  };\n}\n\n/**\n * Escape a regular expression string.\n */\nfunction escapeString(str: string) {\n  return str.replace(/([.+*?=^!:${}()[\\]|/\\\\])/g, \"\\\\$1\");\n}\n\n/**\n * Get the flags for a regexp from the options.\n */\nfunction flags(options?: { sensitive?: boolean }) {\n  return options && options.sensitive ? \"\" : \"i\";\n}\n\n/**\n * Metadata about a key.\n */\nexport interface Key {\n  name: string | number;\n  prefix: string;\n  suffix: string;\n  pattern: string;\n  modifier: string;\n}\n\n/**\n * A token is a string (nothing special) or key metadata (capture group).\n */\nexport type Token = string | Key;\n\n/**\n * Pull out keys from a regexp.\n */\nfunction regexpToRegexp(path: RegExp, keys?: Key[]): RegExp {\n  if (!keys) return path;\n\n  const groupsRegex = /\\((?:\\?<(.*?)>)?(?!\\?)/g;\n\n  let index = 0;\n  let execResult = groupsRegex.exec(path.source);\n  while (execResult) {\n    keys.push({\n      // Use parenthesized substring match if available, index otherwise\n      name: execResult[1] || index++,\n      prefix: \"\",\n      suffix: \"\",\n      modifier: \"\",\n      pattern: \"\",\n    });\n    execResult = groupsRegex.exec(path.source);\n  }\n\n  return path;\n}\n\n/**\n * Transform an array into a regexp.\n */\nfunction arrayToRegexp(\n  paths: Array<string | RegExp>,\n  keys?: Key[],\n  options?: TokensToRegexpOptions & ParseOptions,\n): RegExp {\n  const parts = paths.map((path) => pathToRegexp(path, keys, options).source);\n  return new RegExp(`(?:${parts.join(\"|\")})`, flags(options));\n}\n\n/**\n * Create a path regexp from string input.\n */\nfunction stringToRegexp(\n  path: string,\n  keys?: Key[],\n  options?: TokensToRegexpOptions & ParseOptions,\n) {\n  return tokensToRegexp(parse(path, options), keys, options);\n}\n\nexport interface TokensToRegexpOptions {\n  /**\n   * When `true` the regexp will be case sensitive. (default: `false`)\n   */\n  sensitive?: boolean;\n  /**\n   * When `true` the regexp won't allow an optional trailing delimiter to match. (default: `false`)\n   */\n  strict?: boolean;\n  /**\n   * When `true` the regexp will match to the end of the string. (default: `true`)\n   */\n  end?: boolean;\n  /**\n   * When `true` the regexp will match from the beginning of the string. (default: `true`)\n   */\n  start?: boolean;\n  /**\n   * Sets the final character for non-ending optimistic matches. (default: `/`)\n   */\n  delimiter?: string;\n  /**\n   * List of characters that can also be \"end\" characters.\n   */\n  endsWith?: string;\n  /**\n   * Encode path tokens for use in the `RegExp`.\n   */\n  encode?: (value: string) => string;\n}\n\n/**\n * Expose a function for taking tokens and returning a RegExp.\n */\nexport function tokensToRegexp(\n  tokens: Token[],\n  keys?: Key[],\n  options: TokensToRegexpOptions = {},\n) {\n  const {\n    strict = false,\n    start = true,\n    end = true,\n    encode = (x: string) => x,\n    delimiter = \"/#?\",\n    endsWith = \"\",\n  } = options;\n  const endsWithRe = `[${escapeString(endsWith)}]|$`;\n  const delimiterRe = `[${escapeString(delimiter)}]`;\n  let route = start ? \"^\" : \"\";\n\n  // Iterate over the tokens and create our regexp string.\n  for (const token of tokens) {\n    if (typeof token === \"string\") {\n      route += escapeString(encode(token));\n    } else {\n      const prefix = escapeString(encode(token.prefix));\n      const suffix = escapeString(encode(token.suffix));\n\n      if (token.pattern) {\n        if (keys) keys.push(token);\n\n        if (prefix || suffix) {\n          if (token.modifier === \"+\" || token.modifier === \"*\") {\n            const mod = token.modifier === \"*\" ? \"?\" : \"\";\n            route += `(?:${prefix}((?:${token.pattern})(?:${suffix}${prefix}(?:${token.pattern}))*)${suffix})${mod}`;\n          } else {\n            route += `(?:${prefix}(${token.pattern})${suffix})${token.modifier}`;\n          }\n        } else {\n          if (token.modifier === \"+\" || token.modifier === \"*\") {\n            throw new TypeError(\n              `Can not repeat \"${token.name}\" without a prefix and suffix`,\n            );\n          }\n\n          route += `(${token.pattern})${token.modifier}`;\n        }\n      } else {\n        route += `(?:${prefix}${suffix})${token.modifier}`;\n      }\n    }\n  }\n\n  if (end) {\n    if (!strict) route += `${delimiterRe}?`;\n\n    route += !options.endsWith ? \"$\" : `(?=${endsWithRe})`;\n  } else {\n    const endToken = tokens[tokens.length - 1];\n    const isEndDelimited =\n      typeof endToken === \"string\"\n        ? delimiterRe.indexOf(endToken[endToken.length - 1]) > -1\n        : endToken === undefined;\n\n    if (!strict) {\n      route += `(?:${delimiterRe}(?=${endsWithRe}))?`;\n    }\n\n    if (!isEndDelimited) {\n      route += `(?=${delimiterRe}|${endsWithRe})`;\n    }\n  }\n\n  return new RegExp(route, flags(options));\n}\n\n/**\n * Supported `path-to-regexp` input types.\n */\nexport type Path = string | RegExp | Array<string | RegExp>;\n\n/**\n * Normalize the given path string, returning a regular expression.\n *\n * An empty array can be passed in for the keys, which will hold the\n * placeholder key descriptions. For example, using `/user/:id`, `keys` will\n * contain `[{ name: 'id', delimiter: '/', optional: false, repeat: false }]`.\n */\nexport function pathToRegexp(\n  path: Path,\n  keys?: Key[],\n  options?: TokensToRegexpOptions & ParseOptions,\n) {\n  if (path instanceof RegExp) return regexpToRegexp(path, keys);\n  if (Array.isArray(path)) return arrayToRegexp(path, keys, options);\n  return stringToRegexp(path, keys, options);\n}\n", "import { match } from \"path-to-regexp\";\n\n//note: this explicitly does not include the * character, as pages requires this\nconst escapeRegex = /[.+?^${}()|[\\]\\\\]/g;\n\ntype HTTPMethod =\n\t| \"HEAD\"\n\t| \"OPTIONS\"\n\t| \"GET\"\n\t| \"POST\"\n\t| \"PUT\"\n\t| \"PATCH\"\n\t| \"DELETE\";\n\n/* TODO: Grab these from @cloudflare/workers-types instead */\ntype Params<P extends string = string> = Record<P, string | string[]>;\n\ntype EventContext<Env, P extends string, Data> = {\n\trequest: Request;\n\tfunctionPath: string;\n\twaitUntil: (promise: Promise<unknown>) => void;\n\tpassThroughOnException: () => void;\n\tnext: (input?: Request | string, init?: RequestInit) => Promise<Response>;\n\tenv: Env & { ASSETS: { fetch: typeof fetch } };\n\tparams: Params<P>;\n\tdata: Data;\n};\n\ndeclare type PagesFunction<\n\tEnv = unknown,\n\tP extends string = string,\n\tData extends Record<string, unknown> = Record<string, unknown>,\n> = (context: EventContext<Env, P, Data>) => Response | Promise<Response>;\n/* end @cloudflare/workers-types */\n\ntype RouteHandler = {\n\troutePath: string;\n\tmountPath: string;\n\tmethod?: HTTPMethod;\n\tmodules: PagesFunction[];\n\tmiddlewares: PagesFunction[];\n};\n\n// inject `routes` via ESBuild\ndeclare const routes: RouteHandler[];\n// define `__FALLBACK_SERVICE__` via ESBuild\ndeclare const __FALLBACK_SERVICE__: string;\n\n// expect an ASSETS fetcher binding pointing to the asset-server stage\ntype FetchEnv = {\n\t[name: string]: { fetch: typeof fetch };\n\tASSETS: { fetch: typeof fetch };\n};\n\ntype WorkerContext = {\n\twaitUntil: (promise: Promise<unknown>) => void;\n\tpassThroughOnException: () => void;\n};\n\nfunction* executeRequest(request: Request) {\n\tconst requestPath = new URL(request.url).pathname;\n\n\t// First, iterate through the routes (backwards) and execute \"middlewares\" on partial route matches\n\tfor (const route of [...routes].reverse()) {\n\t\tif (route.method && route.method !== request.method) {\n\t\t\tcontinue;\n\t\t}\n\n\t\t// replaces with \"\\\\$&\", this prepends a backslash to the matched string, e.g. \"[\" becomes \"\\[\"\n\t\tconst routeMatcher = match(route.routePath.replace(escapeRegex, \"\\\\$&\"), {\n\t\t\tend: false,\n\t\t});\n\t\tconst mountMatcher = match(route.mountPath.replace(escapeRegex, \"\\\\$&\"), {\n\t\t\tend: false,\n\t\t});\n\t\tconst matchResult = routeMatcher(requestPath);\n\t\tconst mountMatchResult = mountMatcher(requestPath);\n\t\tif (matchResult && mountMatchResult) {\n\t\t\tfor (const handler of route.middlewares.flat()) {\n\t\t\t\tyield {\n\t\t\t\t\thandler,\n\t\t\t\t\tparams: matchResult.params as Params,\n\t\t\t\t\tpath: mountMatchResult.path,\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\t}\n\n\t// Then look for the first exact route match and execute its \"modules\"\n\tfor (const route of routes) {\n\t\tif (route.method && route.method !== request.method) {\n\t\t\tcontinue;\n\t\t}\n\t\tconst routeMatcher = match(route.routePath.replace(escapeRegex, \"\\\\$&\"), {\n\t\t\tend: true,\n\t\t});\n\t\tconst mountMatcher = match(route.mountPath.replace(escapeRegex, \"\\\\$&\"), {\n\t\t\tend: false,\n\t\t});\n\t\tconst matchResult = routeMatcher(requestPath);\n\t\tconst mountMatchResult = mountMatcher(requestPath);\n\t\tif (matchResult && mountMatchResult && route.modules.length) {\n\t\t\tfor (const handler of route.modules.flat()) {\n\t\t\t\tyield {\n\t\t\t\t\thandler,\n\t\t\t\t\tparams: matchResult.params as Params,\n\t\t\t\t\tpath: matchResult.path,\n\t\t\t\t};\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nexport default {\n\tasync fetch(\n\t\toriginalRequest: Request,\n\t\tenv: FetchEnv,\n\t\tworkerContext: WorkerContext\n\t) {\n\t\tlet request = originalRequest;\n\t\tconst handlerIterator = executeRequest(request);\n\t\tlet data = {}; // arbitrary data the user can set between functions\n\t\tlet isFailOpen = false;\n\n\t\tconst next = async (input?: RequestInfo, init?: RequestInit) => {\n\t\t\tif (input !== undefined) {\n\t\t\t\tlet url = input;\n\t\t\t\tif (typeof input === \"string\") {\n\t\t\t\t\turl = new URL(input, request.url).toString();\n\t\t\t\t}\n\t\t\t\trequest = new Request(url, init);\n\t\t\t}\n\n\t\t\tconst result = handlerIterator.next();\n\t\t\t// Note we can't use `!result.done` because this doesn't narrow to the correct type\n\t\t\tif (result.done === false) {\n\t\t\t\tconst { handler, params, path } = result.value;\n\t\t\t\tconst context = {\n\t\t\t\t\trequest: new Request(request.clone()),\n\t\t\t\t\tfunctionPath: path,\n\t\t\t\t\tnext,\n\t\t\t\t\tparams,\n\t\t\t\t\tget data() {\n\t\t\t\t\t\treturn data;\n\t\t\t\t\t},\n\t\t\t\t\tset data(value) {\n\t\t\t\t\t\tif (typeof value !== \"object\" || value === null) {\n\t\t\t\t\t\t\tthrow new Error(\"context.data must be an object\");\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// user has overriden context.data, so we need to merge it with the existing data\n\t\t\t\t\t\tdata = value;\n\t\t\t\t\t},\n\t\t\t\t\tenv,\n\t\t\t\t\twaitUntil: workerContext.waitUntil.bind(workerContext),\n\t\t\t\t\tpassThroughOnException: () => {\n\t\t\t\t\t\tisFailOpen = true;\n\t\t\t\t\t},\n\t\t\t\t};\n\n\t\t\t\tconst response = await handler(context);\n\n\t\t\t\tif (!(response instanceof Response)) {\n\t\t\t\t\tthrow new Error(\"Your Pages function should return a Response\");\n\t\t\t\t}\n\n\t\t\t\treturn cloneResponse(response);\n\t\t\t} else if (__FALLBACK_SERVICE__) {\n\t\t\t\t// There are no more handlers so finish with the fallback service (`env.ASSETS.fetch` in Pages' case)\n\t\t\t\tconst response = await env[__FALLBACK_SERVICE__].fetch(request);\n\t\t\t\treturn cloneResponse(response);\n\t\t\t} else {\n\t\t\t\t// There was not fallback service so actually make the request to the origin.\n\t\t\t\tconst response = await fetch(request);\n\t\t\t\treturn cloneResponse(response);\n\t\t\t}\n\t\t};\n\n\t\ttry {\n\t\t\treturn await next();\n\t\t} catch (error) {\n\t\t\tif (isFailOpen) {\n\t\t\t\tconst response = await env[__FALLBACK_SERVICE__].fetch(request);\n\t\t\t\treturn cloneResponse(response);\n\t\t\t}\n\n\t\t\tthrow error;\n\t\t}\n\t},\n};\n\n// This makes a Response mutable\nconst cloneResponse = (response: Response) =>\n\t// https://fetch.spec.whatwg.org/#null-body-status\n\tnew Response(\n\t\t[101, 204, 205, 304].includes(response.status) ? null : response.body,\n\t\tresponse\n\t);\n", "import type { Middleware } from \"./common\";\n\nconst drainBody: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} finally {\n\t\ttry {\n\t\t\tif (request.body !== null && !request.bodyUsed) {\n\t\t\t\tconst reader = request.body.getReader();\n\t\t\t\twhile (!(await reader.read()).done) {}\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tconsole.error(\"Failed to drain the unused request body.\", e);\n\t\t}\n\t}\n};\n\nexport default drainBody;\n", "import type { Middleware } from \"./common\";\n\ninterface JsonError {\n\tmessage?: string;\n\tname?: string;\n\tstack?: string;\n\tcause?: JsonError;\n}\n\nfunction reduceError(e: any): JsonError {\n\treturn {\n\t\tname: e?.name,\n\t\tmessage: e?.message ?? String(e),\n\t\tstack: e?.stack,\n\t\tcause: e?.cause === undefined ? undefined : reduceError(e.cause),\n\t};\n}\n\n// See comment in `bundle.ts` for details on why this is needed\nconst jsonError: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} catch (e: any) {\n\t\tconst error = reduceError(e);\n\t\treturn Response.json(error, {\n\t\t\tstatus: 500,\n\t\t\theaders: { \"MF-Experimental-Error-Stack\": \"true\" },\n\t\t});\n\t}\n};\n\nexport default jsonError;\n", "\t\t\t\timport worker, * as OTHER_EXPORTS from \"/opt/homebrew/lib/node_modules/wrangler/templates/pages-template-worker.ts\";\n\t\t\t\timport * as __MIDDLEWARE_0__ from \"/opt/homebrew/lib/node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts\";\nimport * as __MIDDLEWARE_1__ from \"/opt/homebrew/lib/node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts\";\n\n\t\t\t\texport * from \"/opt/homebrew/lib/node_modules/wrangler/templates/pages-template-worker.ts\";\n\t\t\t\tconst MIDDLEWARE_TEST_INJECT = \"__INJECT_FOR_TESTING_WRANGLER_MIDDLEWARE__\";\n\t\t\t\texport const __INTERNAL_WRANGLER_MIDDLEWARE__ = [\n\t\t\t\t\t\n\t\t\t\t\t__MIDDLEWARE_0__.default,__MIDDLEWARE_1__.default\n\t\t\t\t]\n\t\t\t\texport default worker;", "export type Awaitable<T> = T | Promise<T>;\n// TODO: allow dispatching more events?\nexport type Dispatcher = (\n\ttype: \"scheduled\",\n\tinit: { cron?: string }\n) => Awaitable<void>;\n\nexport type IncomingRequest = Request<\n\tunknown,\n\tIncomingRequestCfProperties<unknown>\n>;\n\nexport interface MiddlewareContext {\n\tdispatch: Dispatcher;\n\tnext(request: IncomingRequest, env: any): Awaitable<Response>;\n}\n\nexport type Middleware = (\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tmiddlewareCtx: MiddlewareContext\n) => Awaitable<Response>;\n\nconst __facade_middleware__: Middleware[] = [];\n\n// The register functions allow for the insertion of one or many middleware,\n// We register internal middleware first in the stack, but have no way of controlling\n// the order that addMiddleware is run in service workers so need an internal function.\nexport function __facade_register__(...args: (Middleware | Middleware[])[]) {\n\t__facade_middleware__.push(...args.flat());\n}\nexport function __facade_registerInternal__(\n\t...args: (Middleware | Middleware[])[]\n) {\n\t__facade_middleware__.unshift(...args.flat());\n}\n\nfunction __facade_invokeChain__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tmiddlewareChain: Middleware[]\n): Awaitable<Response> {\n\tconst [head, ...tail] = middlewareChain;\n\tconst middlewareCtx: MiddlewareContext = {\n\t\tdispatch,\n\t\tnext(newRequest, newEnv) {\n\t\t\treturn __facade_invokeChain__(newRequest, newEnv, ctx, dispatch, tail);\n\t\t},\n\t};\n\treturn head(request, env, ctx, middlewareCtx);\n}\n\nexport function __facade_invoke__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tfinalMiddleware: Middleware\n): Awaitable<Response> {\n\treturn __facade_invokeChain__(request, env, ctx, dispatch, [\n\t\t...__facade_middleware__,\n\t\tfinalMiddleware,\n\t]);\n}\n", "// This loads all middlewares exposed on the middleware object and then starts\n// the invocation chain. The big idea is that we can add these to the middleware\n// export dynamically through wrangler, or we can potentially let users directly\n// add them as a sort of \"plugin\" system.\n\nimport ENTRY, { __INTERNAL_WRANGLER_MIDDLEWARE__ } from \"/Users/eziopappalardo/Documents/cucina/.wrangler/tmp/bundle-4uoDjQ/middleware-insertion-facade.js\";\nimport { __facade_invoke__, __facade_register__, Dispatcher } from \"/opt/homebrew/lib/node_modules/wrangler/templates/middleware/common.ts\";\nimport type { WorkerEntrypointConstructor } from \"/Users/eziopappalardo/Documents/cucina/.wrangler/tmp/bundle-4uoDjQ/middleware-insertion-facade.js\";\n\n// Preserve all the exports from the worker\nexport * from \"/Users/eziopappalardo/Documents/cucina/.wrangler/tmp/bundle-4uoDjQ/middleware-insertion-facade.js\";\n\nclass __Facade_ScheduledController__ implements ScheduledController {\n\treadonly #noRetry: ScheduledController[\"noRetry\"];\n\n\tconstructor(\n\t\treadonly scheduledTime: number,\n\t\treadonly cron: string,\n\t\tnoRetry: ScheduledController[\"noRetry\"]\n\t) {\n\t\tthis.#noRetry = noRetry;\n\t}\n\n\tnoRetry() {\n\t\tif (!(this instanceof __Facade_ScheduledController__)) {\n\t\t\tthrow new TypeError(\"Illegal invocation\");\n\t\t}\n\t\t// Need to call native method immediately in case uncaught error thrown\n\t\tthis.#noRetry();\n\t}\n}\n\nfunction wrapExportedHandler(worker: ExportedHandler): ExportedHandler {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn worker;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\tconst fetchDispatcher: ExportedHandlerFetchHandler = function (\n\t\trequest,\n\t\tenv,\n\t\tctx\n\t) {\n\t\tif (worker.fetch === undefined) {\n\t\t\tthrow new Error(\"Handler does not export a fetch() function.\");\n\t\t}\n\t\treturn worker.fetch(request, env, ctx);\n\t};\n\n\treturn {\n\t\t...worker,\n\t\tfetch(request, env, ctx) {\n\t\t\tconst dispatcher: Dispatcher = function (type, init) {\n\t\t\t\tif (type === \"scheduled\" && worker.scheduled !== undefined) {\n\t\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\t\tDate.now(),\n\t\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t\t() => {}\n\t\t\t\t\t);\n\t\t\t\t\treturn worker.scheduled(controller, env, ctx);\n\t\t\t\t}\n\t\t\t};\n\t\t\treturn __facade_invoke__(request, env, ctx, dispatcher, fetchDispatcher);\n\t\t},\n\t};\n}\n\nfunction wrapWorkerEntrypoint(\n\tklass: WorkerEntrypointConstructor\n): WorkerEntrypointConstructor {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn klass;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\t// `extend`ing `klass` here so other RPC methods remain callable\n\treturn class extends klass {\n\t\t#fetchDispatcher: ExportedHandlerFetchHandler<Record<string, unknown>> = (\n\t\t\trequest,\n\t\t\tenv,\n\t\t\tctx\n\t\t) => {\n\t\t\tthis.env = env;\n\t\t\tthis.ctx = ctx;\n\t\t\tif (super.fetch === undefined) {\n\t\t\t\tthrow new Error(\"Entrypoint class does not define a fetch() function.\");\n\t\t\t}\n\t\t\treturn super.fetch(request);\n\t\t};\n\n\t\t#dispatcher: Dispatcher = (type, init) => {\n\t\t\tif (type === \"scheduled\" && super.scheduled !== undefined) {\n\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\tDate.now(),\n\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t() => {}\n\t\t\t\t);\n\t\t\t\treturn super.scheduled(controller);\n\t\t\t}\n\t\t};\n\n\t\tfetch(request: Request<unknown, IncomingRequestCfProperties>) {\n\t\t\treturn __facade_invoke__(\n\t\t\t\trequest,\n\t\t\t\tthis.env,\n\t\t\t\tthis.ctx,\n\t\t\t\tthis.#dispatcher,\n\t\t\t\tthis.#fetchDispatcher\n\t\t\t);\n\t\t}\n\t};\n}\n\nlet WRAPPED_ENTRY: ExportedHandler | WorkerEntrypointConstructor | undefined;\nif (typeof ENTRY === \"object\") {\n\tWRAPPED_ENTRY = wrapExportedHandler(ENTRY);\n} else if (typeof ENTRY === \"function\") {\n\tWRAPPED_ENTRY = wrapWorkerEntrypoint(ENTRY);\n}\nexport default WRAPPED_ENTRY;\n"],
  "mappings": ";;;;AAMO,IAAM,gBAAoC,8BAAO,YAAY;AAClE,QAAM,EAAE,SAAS,IAAI,IAAI;AAEzB,QAAM,cAAc;AAAA,IAClB,+BAA+B;AAAA,IAC/B,gCAAgC;AAAA,IAChC,gCAAgC;AAAA,EAClC;AAEA,MAAI;AACF,UAAM,EAAE,MAAM,IAAI,MAAM,QAAQ,KAAK;AAErC,QAAI,CAAC,OAAO;AACV,aAAO,IAAI,SAAS,KAAK,UAAU,EAAE,OAAO,oBAAoB,CAAC,GAAG;AAAA,QAClE,QAAQ;AAAA,QACR,SAAS,EAAE,gBAAgB,oBAAoB,GAAG,YAAY;AAAA,MAChE,CAAC;AAAA,IACH;AAGA,UAAM,UAAU,MAAM,MAAM,4BAA4B;AACxD,QAAI,CAAC,SAAS;AACZ,aAAO,IAAI,SAAS,KAAK,UAAU,EAAE,OAAO,uBAAuB,CAAC,GAAG;AAAA,QACrE,QAAQ;AAAA,QACR,SAAS,EAAE,gBAAgB,oBAAoB,GAAG,YAAY;AAAA,MAChE,CAAC;AAAA,IACH;AAEA,UAAM,YAAY,QAAQ,CAAC;AAC3B,UAAM,YAAY,QAAQ,CAAC;AAG3B,UAAM,WAAW,MAAM,MAAM,yCAAyC;AAAA,MACpE,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,QAChB,aAAa,IAAI;AAAA,QACjB,qBAAqB;AAAA,MACvB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,OAAO;AAAA,QACP,YAAY;AAAA,QACZ,UAAU;AAAA,UACR;AAAA,YACE,MAAM;AAAA,YACN,SAAS;AAAA,cACP;AAAA,gBACE,MAAM;AAAA,gBACN,QAAQ;AAAA,kBACN,MAAM;AAAA,kBACN,YAAY;AAAA,kBACZ,MAAM;AAAA,gBACR;AAAA,cACF;AAAA,cACA;AAAA,gBACE,MAAM;AAAA,gBACN,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAiBR;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,QAAQ,MAAM,SAAS,KAAK;AAClC,cAAQ,MAAM,4BAA4B,KAAK;AAC/C,aAAO,IAAI,SAAS,KAAK,UAAU,EAAE,OAAO,mBAAmB,CAAC,GAAG;AAAA,QACjE,QAAQ;AAAA,QACR,SAAS,EAAE,gBAAgB,oBAAoB,GAAG,YAAY;AAAA,MAChE,CAAC;AAAA,IACH;AAEA,UAAM,SAAS,MAAM,SAAS,KAAK;AAKnC,UAAM,cAAc,OAAO,QAAQ,KAAK,OAAK,EAAE,SAAS,MAAM;AAC9D,QAAI,CAAC,aAAa,MAAM;AACtB,aAAO,IAAI,SAAS,KAAK,UAAU,EAAE,OAAO,sBAAsB,CAAC,GAAG;AAAA,QACpE,QAAQ;AAAA,QACR,SAAS,EAAE,gBAAgB,oBAAoB,GAAG,YAAY;AAAA,MAChE,CAAC;AAAA,IACH;AAGA,QAAI;AAEF,UAAI,WAAW,YAAY;AAC3B,YAAM,YAAY,SAAS,MAAM,8BAA8B;AAC/D,UAAI,WAAW;AACb,mBAAW,UAAU,CAAC,EAAE,KAAK;AAAA,MAC/B;AAEA,YAAM,cAAc,KAAK,MAAM,QAAQ;AACvC,aAAO,IAAI,SAAS,KAAK,UAAU,WAAW,GAAG;AAAA,QAC/C,SAAS,EAAE,gBAAgB,oBAAoB,GAAG,YAAY;AAAA,MAChE,CAAC;AAAA,IACH,SAAS,YAAY;AACnB,cAAQ,MAAM,qBAAqB,YAAY,YAAY,IAAI;AAC/D,aAAO,IAAI,SAAS,KAAK,UAAU;AAAA,QACjC,OAAO;AAAA,QACP,KAAK,YAAY;AAAA,MACnB,CAAC,GAAG;AAAA,QACF,QAAQ;AAAA,QACR,SAAS,EAAE,gBAAgB,oBAAoB,GAAG,YAAY;AAAA,MAChE,CAAC;AAAA,IACH;AAAA,EAEF,SAAS,OAAO;AACd,YAAQ,MAAM,yBAAyB,KAAK;AAC5C,WAAO,IAAI,SAAS,KAAK,UAAU,EAAE,OAAO,wBAAwB,CAAC,GAAG;AAAA,MACtE,QAAQ;AAAA,MACR,SAAS,EAAE,gBAAgB,oBAAoB,GAAG,YAAY;AAAA,IAChE,CAAC;AAAA,EACH;AACF,GArIiD;AAwI1C,IAAM,mBAAkC,mCAAY;AACzD,SAAO,IAAI,SAAS,MAAM;AAAA,IACxB,SAAS;AAAA,MACP,+BAA+B;AAAA,MAC/B,gCAAgC;AAAA,MAChC,gCAAgC;AAAA,IAClC;AAAA,EACF,CAAC;AACH,GAR+C;;;ACvI/C,IAAI,WAA4B;AAchC,SAAS,SAAS,MAAwB;AACxC,SAAO,KAAK,YAAY,EACrB,QAAQ,uBAAuB,GAAG,EAClC,MAAM,KAAK,EACX,OAAO,OAAK,EAAE,SAAS,CAAC;AAC7B;AALS;AAOT,SAAS,iBAAiB,OAAiB,KAAe,WAA2B;AACnF,QAAM,KAAK;AACX,QAAM,IAAI;AACV,QAAM,SAAS,IAAI;AAEnB,MAAI,QAAQ;AACZ,QAAM,UAAU,oBAAI,IAAoB;AAExC,aAAW,QAAQ,KAAK;AACtB,YAAQ,IAAI,OAAO,QAAQ,IAAI,IAAI,KAAK,KAAK,CAAC;AAAA,EAChD;AAEA,aAAW,QAAQ,OAAO;AACxB,UAAM,KAAK,QAAQ,IAAI,IAAI,KAAK;AAChC,QAAI,KAAK,GAAG;AACV,YAAM,MAAM,KAAK,IAAI,IAAI,CAAC;AAC1B,YAAM,SAAU,MAAM,KAAK,MAAO,KAAK,MAAM,IAAI,IAAI,IAAI,SAAS;AAClE,eAAS,MAAM;AAAA,IACjB;AAAA,EACF;AAEA,SAAO;AACT;AAtBS;AAyBT,SAAS,aAAa,OAAe,QAAoB,OAAe,GAAe;AACrF,QAAM,cAAc,SAAS,KAAK;AAGlC,QAAM,YAAY,OAAO,OAAO,CAAC,KAAK,MAAM,MAAM,SAAS,EAAE,GAAG,EAAE,QAAQ,CAAC,IAAI,OAAO;AAGtF,QAAM,SAAS,OAAO,IAAI,YAAU;AAAA,IAClC;AAAA,IACA,OAAO,iBAAiB,aAAa,SAAS,MAAM,GAAG,GAAG,SAAS;AAAA,EACrE,EAAE;AAGF,SAAO,OACJ,OAAO,OAAK,EAAE,QAAQ,CAAC,EACvB,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK,EAChC,MAAM,GAAG,IAAI,EACb,IAAI,OAAK,EAAE,KAAK;AACrB;AAlBS;AAqBT,SAAS,cAAc,QAA4B;AACjD,MAAI,OAAO,WAAW,EAAG,QAAO;AAEhC,MAAI,UAAU;AAEd,aAAW,SAAS,QAAQ;AAC1B,eAAW,GAAG,MAAM,GAAG;AAAA;AAAA;AAAA,EACzB;AAEA,aAAW;AAEX,SAAO;AACT;AAZS;AAcF,IAAMA,iBAAoC,8BAAO,YAAY;AAClE,QAAM,EAAE,SAAS,IAAI,IAAI;AAEzB,QAAM,cAAc;AAAA,IAClB,+BAA+B;AAAA,IAC/B,gCAAgC;AAAA,IAChC,gCAAgC;AAAA,EAClC;AAEA,MAAI;AACF,UAAM,EAAE,SAAS,UAAU,CAAC,GAAG,WAAW,OAAO,WAAW,OAAO,IAAI,MAAM,QAAQ,KAAK;AAO1F,QAAI,CAAC,SAAS;AACZ,aAAO,IAAI,SAAS,KAAK,UAAU,EAAE,OAAO,sBAAsB,CAAC,GAAG;AAAA,QACpE,QAAQ;AAAA,QACR,SAAS,EAAE,gBAAgB,oBAAoB,GAAG,YAAY;AAAA,MAChE,CAAC;AAAA,IACH;AAGA,QAAI,CAAC,UAAU;AACb,UAAI;AACF,cAAM,cAAc,MAAM,MAAM,IAAI,IAAI,mBAAmB,QAAQ,GAAG,CAAC;AACvE,YAAI,YAAY,IAAI;AAClB,qBAAW,MAAM,YAAY,KAAK;AAClC,kBAAQ,IAAI,qBAAqB,SAAS,OAAO,MAAM,SAAS;AAAA,QAClE;AAAA,MACF,SAAS,GAAG;AACV,gBAAQ,IAAI,iDAAiD;AAAA,MAC/D;AAAA,IACF;AAGA,QAAI,aAAa;AACjB,QAAI,YAAY,SAAS,QAAQ;AAC/B,YAAM,iBAAiB,aAAa,SAAS,SAAS,QAAQ,CAAC;AAC/D,UAAI,eAAe,SAAS,GAAG;AAC7B,qBAAa,cAAc,cAAc;AACzC,gBAAQ,IAAI,SAAS,eAAe,MAAM,kBAAkB;AAAA,MAC9D;AAAA,IACF;AAGA,UAAM,WAAW;AAAA,MACf,GAAG;AAAA,MACH,EAAE,MAAM,QAAQ,SAAS,QAAQ;AAAA,IACnC;AAGA,UAAM,eAAe;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAqDvB,WAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAgCT,EAAE;AAAA,EACJ,YAAY,aAAa,SAAS;AAAA;AAAA,gCAGlC,aAAa,YAAY,4HACzB,aAAa,SAAS,uLACtB,aAAa,eAAe,wHAC5B,aAAa,UAAU,yJACvB,aAAa,eAAe,kKAC5B,aAAa,gBAAgB,qJAC7B,aAAa,gBAAgB,uJAC7B,8BACF;AAAA;AAAA;AAAA;AAAA,IAII,EAAE;AAAA,EACJ,UAAU;AAGR,UAAM,WAAW,MAAM,MAAM,yCAAyC;AAAA,MACpE,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,QAChB,aAAa,IAAI;AAAA,QACjB,qBAAqB;AAAA,MACvB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,OAAO;AAAA,QACP,YAAY;AAAA,QACZ,QAAQ;AAAA;AAAA,QACR,QAAQ;AAAA,QACR;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,QAAQ,MAAM,SAAS,KAAK;AAClC,cAAQ,MAAM,wBAAwB,KAAK;AAC3C,aAAO,IAAI,SAAS,KAAK,UAAU,EAAE,OAAO,mBAAmB,CAAC,GAAG;AAAA,QACjE,QAAQ;AAAA,QACR,SAAS,EAAE,gBAAgB,oBAAoB,GAAG,YAAY;AAAA,MAChE,CAAC;AAAA,IACH;AAGA,WAAO,IAAI,SAAS,SAAS,MAAM;AAAA,MACjC,SAAS;AAAA,QACP,gBAAgB;AAAA,QAChB,iBAAiB;AAAA,QACjB,cAAc;AAAA,QACd,GAAG;AAAA,MACL;AAAA,IACF,CAAC;AAAA,EAEH,SAAS,OAAO;AACd,YAAQ,MAAM,eAAe,KAAK;AAClC,WAAO,IAAI,SAAS,KAAK,UAAU,EAAE,OAAO,wBAAwB,CAAC,GAAG;AAAA,MACtE,QAAQ;AAAA,MACR,SAAS,EAAE,gBAAgB,oBAAoB,GAAG,YAAY;AAAA,IAChE,CAAC;AAAA,EACH;AACF,GAzMiD;AA4M1C,IAAMC,oBAAkC,mCAAY;AACzD,SAAO,IAAI,SAAS,MAAM;AAAA,IACxB,SAAS;AAAA,MACP,+BAA+B;AAAA,MAC/B,gCAAgC;AAAA,MAChC,gCAAgC;AAAA,IAClC;AAAA,EACF,CAAC;AACH,GAR+C;;;AC/RxC,IAAM,SAAS;AAAA,EAClB;AAAA,IACE,WAAW;AAAA,IACX,WAAW;AAAA,IACX,QAAQ;AAAA,IACR,aAAa,CAAC;AAAA,IACd,SAAS,CAAC,gBAAwC;AAAA,EACpD;AAAA,EACF;AAAA,IACI,WAAW;AAAA,IACX,WAAW;AAAA,IACX,QAAQ;AAAA,IACR,aAAa,CAAC;AAAA,IACd,SAAS,CAAC,aAAqC;AAAA,EACjD;AAAA,EACF;AAAA,IACI,WAAW;AAAA,IACX,WAAW;AAAA,IACX,QAAQ;AAAA,IACR,aAAa,CAAC;AAAA,IACd,SAAS,CAACC,iBAA8B;AAAA,EAC1C;AAAA,EACF;AAAA,IACI,WAAW;AAAA,IACX,WAAW;AAAA,IACX,QAAQ;AAAA,IACR,aAAa,CAAC;AAAA,IACd,SAAS,CAACC,cAA2B;AAAA,EACvC;AACF;;;ACdF,SAAS,MAAM,KAAW;AACxB,MAAM,SAAqB,CAAA;AAC3B,MAAI,IAAI;AAER,SAAO,IAAI,IAAI,QAAQ;AACrB,QAAM,OAAO,IAAI,CAAC;AAElB,QAAI,SAAS,OAAO,SAAS,OAAO,SAAS,KAAK;AAChD,aAAO,KAAK,EAAE,MAAM,YAAY,OAAO,GAAG,OAAO,IAAI,GAAG,EAAC,CAAE;AAC3D;;AAGF,QAAI,SAAS,MAAM;AACjB,aAAO,KAAK,EAAE,MAAM,gBAAgB,OAAO,KAAK,OAAO,IAAI,GAAG,EAAC,CAAE;AACjE;;AAGF,QAAI,SAAS,KAAK;AAChB,aAAO,KAAK,EAAE,MAAM,QAAQ,OAAO,GAAG,OAAO,IAAI,GAAG,EAAC,CAAE;AACvD;;AAGF,QAAI,SAAS,KAAK;AAChB,aAAO,KAAK,EAAE,MAAM,SAAS,OAAO,GAAG,OAAO,IAAI,GAAG,EAAC,CAAE;AACxD;;AAGF,QAAI,SAAS,KAAK;AAChB,UAAI,OAAO;AACX,UAAI,IAAI,IAAI;AAEZ,aAAO,IAAI,IAAI,QAAQ;AACrB,YAAM,OAAO,IAAI,WAAW,CAAC;AAE7B;;UAEG,QAAQ,MAAM,QAAQ;UAEtB,QAAQ,MAAM,QAAQ;UAEtB,QAAQ,MAAM,QAAQ;UAEvB,SAAS;UACT;AACA,kBAAQ,IAAI,GAAG;AACf;;AAGF;;AAGF,UAAI,CAAC;AAAM,cAAM,IAAI,UAAU,6BAAA,OAA6B,CAAC,CAAE;AAE/D,aAAO,KAAK,EAAE,MAAM,QAAQ,OAAO,GAAG,OAAO,KAAI,CAAE;AACnD,UAAI;AACJ;;AAGF,QAAI,SAAS,KAAK;AAChB,UAAI,QAAQ;AACZ,UAAI,UAAU;AACd,UAAI,IAAI,IAAI;AAEZ,UAAI,IAAI,CAAC,MAAM,KAAK;AAClB,cAAM,IAAI,UAAU,oCAAA,OAAoC,CAAC,CAAE;;AAG7D,aAAO,IAAI,IAAI,QAAQ;AACrB,YAAI,IAAI,CAAC,MAAM,MAAM;AACnB,qBAAW,IAAI,GAAG,IAAI,IAAI,GAAG;AAC7B;;AAGF,YAAI,IAAI,CAAC,MAAM,KAAK;AAClB;AACA,cAAI,UAAU,GAAG;AACf;AACA;;mBAEO,IAAI,CAAC,MAAM,KAAK;AACzB;AACA,cAAI,IAAI,IAAI,CAAC,MAAM,KAAK;AACtB,kBAAM,IAAI,UAAU,uCAAA,OAAuC,CAAC,CAAE;;;AAIlE,mBAAW,IAAI,GAAG;;AAGpB,UAAI;AAAO,cAAM,IAAI,UAAU,yBAAA,OAAyB,CAAC,CAAE;AAC3D,UAAI,CAAC;AAAS,cAAM,IAAI,UAAU,sBAAA,OAAsB,CAAC,CAAE;AAE3D,aAAO,KAAK,EAAE,MAAM,WAAW,OAAO,GAAG,OAAO,QAAO,CAAE;AACzD,UAAI;AACJ;;AAGF,WAAO,KAAK,EAAE,MAAM,QAAQ,OAAO,GAAG,OAAO,IAAI,GAAG,EAAC,CAAE;;AAGzD,SAAO,KAAK,EAAE,MAAM,OAAO,OAAO,GAAG,OAAO,GAAE,CAAE;AAEhD,SAAO;AACT;AAvGS;AAuHH,SAAU,MAAM,KAAa,SAA0B;AAA1B,MAAA,YAAA,QAAA;AAAA,cAAA,CAAA;EAA0B;AAC3D,MAAM,SAAS,MAAM,GAAG;AAChB,MAAA,KAAuC,QAAO,UAA9C,WAAQ,OAAA,SAAG,OAAI,IAAE,KAAsB,QAAO,WAA7B,YAAS,OAAA,SAAG,QAAK;AAC1C,MAAM,SAAkB,CAAA;AACxB,MAAI,MAAM;AACV,MAAI,IAAI;AACR,MAAI,OAAO;AAEX,MAAM,aAAa,gCAAC,MAAsB;AACxC,QAAI,IAAI,OAAO,UAAU,OAAO,CAAC,EAAE,SAAS;AAAM,aAAO,OAAO,GAAG,EAAE;EACvE,GAFmB;AAInB,MAAM,cAAc,gCAAC,MAAsB;AACzC,QAAMC,SAAQ,WAAW,IAAI;AAC7B,QAAIA,WAAU;AAAW,aAAOA;AAC1B,QAAAC,MAA4B,OAAO,CAAC,GAA5B,WAAQA,IAAA,MAAE,QAAKA,IAAA;AAC7B,UAAM,IAAI,UAAU,cAAA,OAAc,UAAQ,MAAA,EAAA,OAAO,OAAK,aAAA,EAAA,OAAc,IAAI,CAAE;EAC5E,GALoB;AAOpB,MAAM,cAAc,kCAAA;AAClB,QAAIC,UAAS;AACb,QAAIF;AACJ,WAAQA,SAAQ,WAAW,MAAM,KAAK,WAAW,cAAc,GAAI;AACjE,MAAAE,WAAUF;;AAEZ,WAAOE;EACT,GAPoB;AASpB,MAAM,SAAS,gCAACF,QAAa;AAC3B,aAAmB,KAAA,GAAA,cAAA,WAAA,KAAA,YAAA,QAAA,MAAS;AAAvB,UAAMG,QAAI,YAAA,EAAA;AAAe,UAAIH,OAAM,QAAQG,KAAI,IAAI;AAAI,eAAO;;AACnE,WAAO;EACT,GAHe;AAKf,MAAM,cAAc,gCAACC,SAAc;AACjC,QAAM,OAAO,OAAO,OAAO,SAAS,CAAC;AACrC,QAAM,WAAWA,YAAW,QAAQ,OAAO,SAAS,WAAW,OAAO;AAEtE,QAAI,QAAQ,CAAC,UAAU;AACrB,YAAM,IAAI,UACR,8DAAA,OAA+D,KAAa,MAAI,GAAA,CAAG;;AAIvF,QAAI,CAAC,YAAY,OAAO,QAAQ;AAAG,aAAO,KAAA,OAAK,aAAa,SAAS,GAAC,KAAA;AACtE,WAAO,SAAA,OAAS,aAAa,QAAQ,GAAC,KAAA,EAAA,OAAM,aAAa,SAAS,GAAC,MAAA;EACrE,GAZoB;AAcpB,SAAO,IAAI,OAAO,QAAQ;AACxB,QAAM,OAAO,WAAW,MAAM;AAC9B,QAAM,OAAO,WAAW,MAAM;AAC9B,QAAM,UAAU,WAAW,SAAS;AAEpC,QAAI,QAAQ,SAAS;AACnB,UAAI,SAAS,QAAQ;AAErB,UAAI,SAAS,QAAQ,MAAM,MAAM,IAAI;AACnC,gBAAQ;AACR,iBAAS;;AAGX,UAAI,MAAM;AACR,eAAO,KAAK,IAAI;AAChB,eAAO;;AAGT,aAAO,KAAK;QACV,MAAM,QAAQ;QACd;QACA,QAAQ;QACR,SAAS,WAAW,YAAY,MAAM;QACtC,UAAU,WAAW,UAAU,KAAK;OACrC;AACD;;AAGF,QAAM,QAAQ,QAAQ,WAAW,cAAc;AAC/C,QAAI,OAAO;AACT,cAAQ;AACR;;AAGF,QAAI,MAAM;AACR,aAAO,KAAK,IAAI;AAChB,aAAO;;AAGT,QAAM,OAAO,WAAW,MAAM;AAC9B,QAAI,MAAM;AACR,UAAM,SAAS,YAAW;AAC1B,UAAM,SAAO,WAAW,MAAM,KAAK;AACnC,UAAM,YAAU,WAAW,SAAS,KAAK;AACzC,UAAM,SAAS,YAAW;AAE1B,kBAAY,OAAO;AAEnB,aAAO,KAAK;QACV,MAAM,WAAS,YAAU,QAAQ;QACjC,SAAS,UAAQ,CAAC,YAAU,YAAY,MAAM,IAAI;QAClD;QACA;QACA,UAAU,WAAW,UAAU,KAAK;OACrC;AACD;;AAGF,gBAAY,KAAK;;AAGnB,SAAO;AACT;AA7GgB;AA4PV,SAAU,MACd,KACA,SAAwE;AAExE,MAAM,OAAc,CAAA;AACpB,MAAM,KAAK,aAAa,KAAK,MAAM,OAAO;AAC1C,SAAO,iBAAoB,IAAI,MAAM,OAAO;AAC9C;AAPgB;AAYV,SAAU,iBACd,IACA,MACA,SAAqC;AAArC,MAAA,YAAA,QAAA;AAAA,cAAA,CAAA;EAAqC;AAE7B,MAAA,KAA8B,QAAO,QAArC,SAAM,OAAA,SAAG,SAAC,GAAS;AAAK,WAAA;EAAA,IAAC;AAEjC,SAAO,SAAU,UAAgB;AAC/B,QAAM,IAAI,GAAG,KAAK,QAAQ;AAC1B,QAAI,CAAC;AAAG,aAAO;AAEP,QAAG,OAAgB,EAAC,CAAA,GAAX,QAAU,EAAC;AAC5B,QAAM,SAAS,uBAAO,OAAO,IAAI;kDAExBC,IAAC;AACR,UAAI,EAAEA,EAAC,MAAM;;AAEb,UAAM,MAAM,KAAKA,KAAI,CAAC;AAEtB,UAAI,IAAI,aAAa,OAAO,IAAI,aAAa,KAAK;AAChD,eAAO,IAAI,IAAI,IAAI,EAAEA,EAAC,EAAE,MAAM,IAAI,SAAS,IAAI,MAAM,EAAE,IAAI,SAAC,OAAK;AAC/D,iBAAO,OAAO,OAAO,GAAG;QAC1B,CAAC;aACI;AACL,eAAO,IAAI,IAAI,IAAI,OAAO,EAAEA,EAAC,GAAG,GAAG;;;AAVvC,aAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAG;cAAxB,CAAC;;AAcV,WAAO,EAAE,MAAM,OAAO,OAAM;EAC9B;AACF;AA9BgB;AAmChB,SAAS,aAAa,KAAW;AAC/B,SAAO,IAAI,QAAQ,6BAA6B,MAAM;AACxD;AAFS;AAOT,SAAS,MAAM,SAAiC;AAC9C,SAAO,WAAW,QAAQ,YAAY,KAAK;AAC7C;AAFS;AAuBT,SAAS,eAAe,MAAc,MAAY;AAChD,MAAI,CAAC;AAAM,WAAO;AAElB,MAAM,cAAc;AAEpB,MAAI,QAAQ;AACZ,MAAI,aAAa,YAAY,KAAK,KAAK,MAAM;AAC7C,SAAO,YAAY;AACjB,SAAK,KAAK;;MAER,MAAM,WAAW,CAAC,KAAK;MACvB,QAAQ;MACR,QAAQ;MACR,UAAU;MACV,SAAS;KACV;AACD,iBAAa,YAAY,KAAK,KAAK,MAAM;;AAG3C,SAAO;AACT;AApBS;AAyBT,SAAS,cACP,OACA,MACA,SAA8C;AAE9C,MAAM,QAAQ,MAAM,IAAI,SAAC,MAAI;AAAK,WAAA,aAAa,MAAM,MAAM,OAAO,EAAE;EAAlC,CAAwC;AAC1E,SAAO,IAAI,OAAO,MAAA,OAAM,MAAM,KAAK,GAAG,GAAC,GAAA,GAAK,MAAM,OAAO,CAAC;AAC5D;AAPS;AAYT,SAAS,eACP,MACA,MACA,SAA8C;AAE9C,SAAO,eAAe,MAAM,MAAM,OAAO,GAAG,MAAM,OAAO;AAC3D;AANS;AA0CH,SAAU,eACd,QACA,MACA,SAAmC;AAAnC,MAAA,YAAA,QAAA;AAAA,cAAA,CAAA;EAAmC;AAGjC,MAAA,KAME,QAAO,QANT,SAAM,OAAA,SAAG,QAAK,IACd,KAKE,QAAO,OALT,QAAK,OAAA,SAAG,OAAI,IACZ,KAIE,QAAO,KAJT,MAAG,OAAA,SAAG,OAAI,IACV,KAGE,QAAO,QAHT,SAAM,OAAA,SAAG,SAAC,GAAS;AAAK,WAAA;EAAA,IAAC,IACzB,KAEE,QAAO,WAFT,YAAS,OAAA,SAAG,QAAK,IACjB,KACE,QAAO,UADT,WAAQ,OAAA,SAAG,KAAE;AAEf,MAAM,aAAa,IAAA,OAAI,aAAa,QAAQ,GAAC,KAAA;AAC7C,MAAM,cAAc,IAAA,OAAI,aAAa,SAAS,GAAC,GAAA;AAC/C,MAAI,QAAQ,QAAQ,MAAM;AAG1B,WAAoB,KAAA,GAAA,WAAA,QAAA,KAAA,SAAA,QAAA,MAAQ;AAAvB,QAAM,QAAK,SAAA,EAAA;AACd,QAAI,OAAO,UAAU,UAAU;AAC7B,eAAS,aAAa,OAAO,KAAK,CAAC;WAC9B;AACL,UAAM,SAAS,aAAa,OAAO,MAAM,MAAM,CAAC;AAChD,UAAM,SAAS,aAAa,OAAO,MAAM,MAAM,CAAC;AAEhD,UAAI,MAAM,SAAS;AACjB,YAAI;AAAM,eAAK,KAAK,KAAK;AAEzB,YAAI,UAAU,QAAQ;AACpB,cAAI,MAAM,aAAa,OAAO,MAAM,aAAa,KAAK;AACpD,gBAAM,MAAM,MAAM,aAAa,MAAM,MAAM;AAC3C,qBAAS,MAAA,OAAM,QAAM,MAAA,EAAA,OAAO,MAAM,SAAO,MAAA,EAAA,OAAO,MAAM,EAAA,OAAG,QAAM,KAAA,EAAA,OAAM,MAAM,SAAO,MAAA,EAAA,OAAO,QAAM,GAAA,EAAA,OAAI,GAAG;iBACjG;AACL,qBAAS,MAAA,OAAM,QAAM,GAAA,EAAA,OAAI,MAAM,SAAO,GAAA,EAAA,OAAI,QAAM,GAAA,EAAA,OAAI,MAAM,QAAQ;;eAE/D;AACL,cAAI,MAAM,aAAa,OAAO,MAAM,aAAa,KAAK;AACpD,kBAAM,IAAI,UACR,mBAAA,OAAmB,MAAM,MAAI,+BAAA,CAA+B;;AAIhE,mBAAS,IAAA,OAAI,MAAM,SAAO,GAAA,EAAA,OAAI,MAAM,QAAQ;;aAEzC;AACL,iBAAS,MAAA,OAAM,MAAM,EAAA,OAAG,QAAM,GAAA,EAAA,OAAI,MAAM,QAAQ;;;;AAKtD,MAAI,KAAK;AACP,QAAI,CAAC;AAAQ,eAAS,GAAA,OAAG,aAAW,GAAA;AAEpC,aAAS,CAAC,QAAQ,WAAW,MAAM,MAAA,OAAM,YAAU,GAAA;SAC9C;AACL,QAAM,WAAW,OAAO,OAAO,SAAS,CAAC;AACzC,QAAM,iBACJ,OAAO,aAAa,WAChB,YAAY,QAAQ,SAAS,SAAS,SAAS,CAAC,CAAC,IAAI,KACrD,aAAa;AAEnB,QAAI,CAAC,QAAQ;AACX,eAAS,MAAA,OAAM,aAAW,KAAA,EAAA,OAAM,YAAU,KAAA;;AAG5C,QAAI,CAAC,gBAAgB;AACnB,eAAS,MAAA,OAAM,aAAW,GAAA,EAAA,OAAI,YAAU,GAAA;;;AAI5C,SAAO,IAAI,OAAO,OAAO,MAAM,OAAO,CAAC;AACzC;AAvEgB;AAqFV,SAAU,aACd,MACA,MACA,SAA8C;AAE9C,MAAI,gBAAgB;AAAQ,WAAO,eAAe,MAAM,IAAI;AAC5D,MAAI,MAAM,QAAQ,IAAI;AAAG,WAAO,cAAc,MAAM,MAAM,OAAO;AACjE,SAAO,eAAe,MAAM,MAAM,OAAO;AAC3C;AARgB;;;ACrnBhB,IAAM,cAAc;AAwDpB,UAAU,eAAe,SAAkB;AAC1C,QAAM,cAAc,IAAI,IAAI,QAAQ,GAAG,EAAE;AAGzC,aAAW,SAAS,CAAC,GAAG,MAAM,EAAE,QAAQ,GAAG;AAC1C,QAAI,MAAM,UAAU,MAAM,WAAW,QAAQ,QAAQ;AACpD;AAAA,IACD;AAGA,UAAM,eAAe,MAAM,MAAM,UAAU,QAAQ,aAAa,MAAM,GAAG;AAAA,MACxE,KAAK;AAAA,IACN,CAAC;AACD,UAAM,eAAe,MAAM,MAAM,UAAU,QAAQ,aAAa,MAAM,GAAG;AAAA,MACxE,KAAK;AAAA,IACN,CAAC;AACD,UAAM,cAAc,aAAa,WAAW;AAC5C,UAAM,mBAAmB,aAAa,WAAW;AACjD,QAAI,eAAe,kBAAkB;AACpC,iBAAW,WAAW,MAAM,YAAY,KAAK,GAAG;AAC/C,cAAM;AAAA,UACL;AAAA,UACA,QAAQ,YAAY;AAAA,UACpB,MAAM,iBAAiB;AAAA,QACxB;AAAA,MACD;AAAA,IACD;AAAA,EACD;AAGA,aAAW,SAAS,QAAQ;AAC3B,QAAI,MAAM,UAAU,MAAM,WAAW,QAAQ,QAAQ;AACpD;AAAA,IACD;AACA,UAAM,eAAe,MAAM,MAAM,UAAU,QAAQ,aAAa,MAAM,GAAG;AAAA,MACxE,KAAK;AAAA,IACN,CAAC;AACD,UAAM,eAAe,MAAM,MAAM,UAAU,QAAQ,aAAa,MAAM,GAAG;AAAA,MACxE,KAAK;AAAA,IACN,CAAC;AACD,UAAM,cAAc,aAAa,WAAW;AAC5C,UAAM,mBAAmB,aAAa,WAAW;AACjD,QAAI,eAAe,oBAAoB,MAAM,QAAQ,QAAQ;AAC5D,iBAAW,WAAW,MAAM,QAAQ,KAAK,GAAG;AAC3C,cAAM;AAAA,UACL;AAAA,UACA,QAAQ,YAAY;AAAA,UACpB,MAAM,YAAY;AAAA,QACnB;AAAA,MACD;AACA;AAAA,IACD;AAAA,EACD;AACD;AArDU;AAuDV,IAAO,gCAAQ;AAAA,EACd,MAAM,MACL,iBACA,KACA,eACC;AACD,QAAI,UAAU;AACd,UAAM,kBAAkB,eAAe,OAAO;AAC9C,QAAI,OAAO,CAAC;AACZ,QAAI,aAAa;AAEjB,UAAM,OAAO,8BAAO,OAAqB,SAAuB;AAC/D,UAAI,UAAU,QAAW;AACxB,YAAI,MAAM;AACV,YAAI,OAAO,UAAU,UAAU;AAC9B,gBAAM,IAAI,IAAI,OAAO,QAAQ,GAAG,EAAE,SAAS;AAAA,QAC5C;AACA,kBAAU,IAAI,QAAQ,KAAK,IAAI;AAAA,MAChC;AAEA,YAAM,SAAS,gBAAgB,KAAK;AAEpC,UAAI,OAAO,SAAS,OAAO;AAC1B,cAAM,EAAE,SAAS,QAAQ,KAAK,IAAI,OAAO;AACzC,cAAM,UAAU;AAAA,UACf,SAAS,IAAI,QAAQ,QAAQ,MAAM,CAAC;AAAA,UACpC,cAAc;AAAA,UACd;AAAA,UACA;AAAA,UACA,IAAI,OAAO;AACV,mBAAO;AAAA,UACR;AAAA,UACA,IAAI,KAAK,OAAO;AACf,gBAAI,OAAO,UAAU,YAAY,UAAU,MAAM;AAChD,oBAAM,IAAI,MAAM,gCAAgC;AAAA,YACjD;AAEA,mBAAO;AAAA,UACR;AAAA,UACA;AAAA,UACA,WAAW,cAAc,UAAU,KAAK,aAAa;AAAA,UACrD,wBAAwB,6BAAM;AAC7B,yBAAa;AAAA,UACd,GAFwB;AAAA,QAGzB;AAEA,cAAM,WAAW,MAAM,QAAQ,OAAO;AAEtC,YAAI,EAAE,oBAAoB,WAAW;AACpC,gBAAM,IAAI,MAAM,8CAA8C;AAAA,QAC/D;AAEA,eAAO,cAAc,QAAQ;AAAA,MAC9B,WAAW,UAAsB;AAEhC,cAAM,WAAW,MAAM,IAAI,QAAoB,EAAE,MAAM,OAAO;AAC9D,eAAO,cAAc,QAAQ;AAAA,MAC9B,OAAO;AAEN,cAAM,WAAW,MAAM,MAAM,OAAO;AACpC,eAAO,cAAc,QAAQ;AAAA,MAC9B;AAAA,IACD,GAnDa;AAqDb,QAAI;AACH,aAAO,MAAM,KAAK;AAAA,IACnB,SAAS,OAAO;AACf,UAAI,YAAY;AACf,cAAM,WAAW,MAAM,IAAI,QAAoB,EAAE,MAAM,OAAO;AAC9D,eAAO,cAAc,QAAQ;AAAA,MAC9B;AAEA,YAAM;AAAA,IACP;AAAA,EACD;AACD;AAGA,IAAM,gBAAgB,wBAAC;AAAA;AAAA,EAEtB,IAAI;AAAA,IACH,CAAC,KAAK,KAAK,KAAK,GAAG,EAAE,SAAS,SAAS,MAAM,IAAI,OAAO,SAAS;AAAA,IACjE;AAAA,EACD;AAAA,GALqB;;;AC9LtB,IAAM,YAAwB,8BAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;AAAA,EAC7C,UAAE;AACD,QAAI;AACH,UAAI,QAAQ,SAAS,QAAQ,CAAC,QAAQ,UAAU;AAC/C,cAAM,SAAS,QAAQ,KAAK,UAAU;AACtC,eAAO,EAAE,MAAM,OAAO,KAAK,GAAG,MAAM;AAAA,QAAC;AAAA,MACtC;AAAA,IACD,SAAS,GAAG;AACX,cAAQ,MAAM,4CAA4C,CAAC;AAAA,IAC5D;AAAA,EACD;AACD,GAb8B;AAe9B,IAAO,6CAAQ;;;ACRf,SAAS,YAAY,GAAmB;AACvC,SAAO;AAAA,IACN,MAAM,GAAG;AAAA,IACT,SAAS,GAAG,WAAW,OAAO,CAAC;AAAA,IAC/B,OAAO,GAAG;AAAA,IACV,OAAO,GAAG,UAAU,SAAY,SAAY,YAAY,EAAE,KAAK;AAAA,EAChE;AACD;AAPS;AAUT,IAAM,YAAwB,8BAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;AAAA,EAC7C,SAAS,GAAQ;AAChB,UAAM,QAAQ,YAAY,CAAC;AAC3B,WAAO,SAAS,KAAK,OAAO;AAAA,MAC3B,QAAQ;AAAA,MACR,SAAS,EAAE,+BAA+B,OAAO;AAAA,IAClD,CAAC;AAAA,EACF;AACD,GAV8B;AAY9B,IAAO,2CAAQ;;;ACzBJ,IAAM,mCAAmC;AAAA,EAE9B;AAAA,EAAyB;AAC3C;AACA,IAAO,sCAAQ;;;ACcnB,IAAM,wBAAsC,CAAC;AAKtC,SAAS,uBAAuB,MAAqC;AAC3E,wBAAsB,KAAK,GAAG,KAAK,KAAK,CAAC;AAC1C;AAFgB;AAShB,SAAS,uBACR,SACA,KACA,KACA,UACA,iBACsB;AACtB,QAAM,CAAC,MAAM,GAAG,IAAI,IAAI;AACxB,QAAM,gBAAmC;AAAA,IACxC;AAAA,IACA,KAAK,YAAY,QAAQ;AACxB,aAAO,uBAAuB,YAAY,QAAQ,KAAK,UAAU,IAAI;AAAA,IACtE;AAAA,EACD;AACA,SAAO,KAAK,SAAS,KAAK,KAAK,aAAa;AAC7C;AAfS;AAiBF,SAAS,kBACf,SACA,KACA,KACA,UACA,iBACsB;AACtB,SAAO,uBAAuB,SAAS,KAAK,KAAK,UAAU;AAAA,IAC1D,GAAG;AAAA,IACH;AAAA,EACD,CAAC;AACF;AAXgB;;;AC3ChB,IAAM,iCAAN,MAAM,gCAA8D;AAAA,EAGnE,YACU,eACA,MACT,SACC;AAHQ;AACA;AAGT,SAAK,WAAW;AAAA,EACjB;AAAA,EArBD,OAYoE;AAAA;AAAA;AAAA,EAC1D;AAAA,EAUT,UAAU;AACT,QAAI,EAAE,gBAAgB,kCAAiC;AACtD,YAAM,IAAI,UAAU,oBAAoB;AAAA,IACzC;AAEA,SAAK,SAAS;AAAA,EACf;AACD;AAEA,SAAS,oBAAoB,QAA0C;AAEtE,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;AAAA,EAC/B;AAEA,QAAM,kBAA+C,gCACpD,SACA,KACA,KACC;AACD,QAAI,OAAO,UAAU,QAAW;AAC/B,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC9D;AACA,WAAO,OAAO,MAAM,SAAS,KAAK,GAAG;AAAA,EACtC,GATqD;AAWrD,SAAO;AAAA,IACN,GAAG;AAAA,IACH,MAAM,SAAS,KAAK,KAAK;AACxB,YAAM,aAAyB,gCAAU,MAAM,MAAM;AACpD,YAAI,SAAS,eAAe,OAAO,cAAc,QAAW;AAC3D,gBAAM,aAAa,IAAI;AAAA,YACtB,KAAK,IAAI;AAAA,YACT,KAAK,QAAQ;AAAA,YACb,MAAM;AAAA,YAAC;AAAA,UACR;AACA,iBAAO,OAAO,UAAU,YAAY,KAAK,GAAG;AAAA,QAC7C;AAAA,MACD,GAT+B;AAU/B,aAAO,kBAAkB,SAAS,KAAK,KAAK,YAAY,eAAe;AAAA,IACxE;AAAA,EACD;AACD;AAxCS;AA0CT,SAAS,qBACR,OAC8B;AAE9B,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;AAAA,EAC/B;AAGA,SAAO,cAAc,MAAM;AAAA,IAC1B,mBAAyE,wBACxE,SACA,KACA,QACI;AACJ,WAAK,MAAM;AACX,WAAK,MAAM;AACX,UAAI,MAAM,UAAU,QAAW;AAC9B,cAAM,IAAI,MAAM,sDAAsD;AAAA,MACvE;AACA,aAAO,MAAM,MAAM,OAAO;AAAA,IAC3B,GAXyE;AAAA,IAazE,cAA0B,wBAAC,MAAM,SAAS;AACzC,UAAI,SAAS,eAAe,MAAM,cAAc,QAAW;AAC1D,cAAM,aAAa,IAAI;AAAA,UACtB,KAAK,IAAI;AAAA,UACT,KAAK,QAAQ;AAAA,UACb,MAAM;AAAA,UAAC;AAAA,QACR;AACA,eAAO,MAAM,UAAU,UAAU;AAAA,MAClC;AAAA,IACD,GAT0B;AAAA,IAW1B,MAAM,SAAwD;AAC7D,aAAO;AAAA,QACN;AAAA,QACA,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,MACN;AAAA,IACD;AAAA,EACD;AACD;AAnDS;AAqDT,IAAI;AACJ,IAAI,OAAO,wCAAU,UAAU;AAC9B,kBAAgB,oBAAoB,mCAAK;AAC1C,WAAW,OAAO,wCAAU,YAAY;AACvC,kBAAgB,qBAAqB,mCAAK;AAC3C;AACA,IAAO,kCAAQ;",
  "names": ["onRequestPost", "onRequestOptions", "onRequestOptions", "onRequestPost", "value", "_a", "result", "char", "prefix", "i"]
}
